{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T23:34:18.928744Z",
     "start_time": "2018-04-01T23:34:18.347617Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from scipy.sparse import csr_matrix\n",
    "import urllib.request\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T23:34:18.945754Z",
     "start_time": "2018-04-01T23:34:18.936618Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_data():\n",
    "    \"\"\" DONE. Download and unzip data.\n",
    "    \"\"\"\n",
    "    url = 'https://www.dropbox.com/s/h9ubx22ftdkyvd5/ml-latest-small.zip?dl=1'\n",
    "    urllib.request.urlretrieve(url, 'ml-latest-small.zip')\n",
    "    zfile = zipfile.ZipFile('ml-latest-small.zip')\n",
    "    zfile.extractall()\n",
    "    zfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T23:34:19.674357Z",
     "start_time": "2018-04-01T23:34:19.668621Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_string(my_string):\n",
    "    \"\"\" DONE. You should use this in your tokenize function.\n",
    "    \"\"\"\n",
    "    return re.findall('[\\w\\-]+', my_string.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T23:34:20.470130Z",
     "start_time": "2018-04-01T23:34:20.464926Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(movies):\n",
    "    \"\"\"\n",
    "    Append a new column to the movies DataFrame with header 'tokens'.\n",
    "    This will contain a list of strings, one per token, extracted\n",
    "    from the 'genre' field of each movie. Use the tokenize_string method above.\n",
    "\n",
    "    Note: you may modify the movies parameter directly; no need to make\n",
    "    a new copy.\n",
    "    Params:\n",
    "      movies...The movies DataFrame\n",
    "    Returns:\n",
    "      The movies DataFrame, augmented to include a new column called 'tokens'.\n",
    "\n",
    "    >>> movies = pd.DataFrame([[123, 'Horror|Romance'], [456, 'Sci-Fi']], columns=['movieId', 'genres'])\n",
    "    >>> movies = tokenize(movies)\n",
    "    >>> movies['tokens'].tolist()\n",
    "    [['horror', 'romance'], ['sci-fi']]\n",
    "    \"\"\"\n",
    "    movies['tokens'] = movies['genres'].apply(tokenize_string)\n",
    "    return movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T23:34:24.012565Z",
     "start_time": "2018-04-01T23:34:23.992355Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['horror', 'romance', 'sci-fi'], ['sci-fi']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.DataFrame([[123, 'Horror|Romance|Sci-Fi'], [456, 'Sci-Fi']], columns=['movieId', 'genres'])\n",
    "movies = tokenize(movies)\n",
    "movies['tokens'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T23:36:16.436977Z",
     "start_time": "2018-04-01T23:36:16.399002Z"
    }
   },
   "outputs": [],
   "source": [
    "def featurize(movies):\n",
    "    \"\"\"\n",
    "    Append a new column to the movies DataFrame with header 'features'.\n",
    "    Each row will contain a csr_matrix of shape (1, num_features). Each\n",
    "    entry in this matrix will contain the tf-idf value of the term, as\n",
    "    defined in class:\n",
    "    tfidf(i, d) := tf(i, d) / max_k tf(k, d) * log10(N/df(i))\n",
    "    where:\n",
    "    i is a term\n",
    "    d is a document (movie)\n",
    "    tf(i, d) is the frequency of term i in document d\n",
    "    max_k tf(k, d) is the maximum frequency of any term in document d\n",
    "    N is the number of documents (movies)\n",
    "    df(i) is the number of unique documents containing term i\n",
    "\n",
    "    Params:\n",
    "      movies...The movies DataFrame\n",
    "    Returns:\n",
    "      A tuple containing:\n",
    "      - The movies DataFrame, which has been modified to include a column named 'features'.\n",
    "      - The vocab, a dict from term to int. Make sure the vocab is sorted alphabetically as in a2 (e.g., {'aardvark': 0, 'boy': 1, ...})\n",
    "    \"\"\"\n",
    "    #create vocab\n",
    "    vocab = dict()\n",
    "    vocabulary = sorted(list(set([voc for vocs in movies.tokens.values for voc in vocs])))\n",
    "    for voc in vocabulary:\n",
    "        vocab[voc] = vocabulary.index(voc)\n",
    "    \n",
    "    \n",
    "    doc_occurences = sum((Counter(set(doc)) for doc in movies.tokens.values), Counter())\n",
    "    \n",
    "    def create_csr(doc):\n",
    "        csr = csr_matrix((1,len(vocab)))\n",
    "        \n",
    "        for token in doc:\n",
    "            freq = doc.count(token)\n",
    "            tfidf = freq*np.log10(len(movies)/doc_occurences[token])\n",
    "            csr[0,vocab[token]] = tfidf\n",
    "        return csr\n",
    "\n",
    "    movies['features'] = movies[\"tokens\"].apply(create_csr)\n",
    "        \n",
    "    return (movies, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T23:36:16.723683Z",
     "start_time": "2018-04-01T23:36:16.695712Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/sparse/compressed.py:774: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-82172e5c0589>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeaturize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-1228f3f8b1ad>\u001b[0m in \u001b[0;36mfeaturize\u001b[0;34m(movies)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcsr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmovies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_csr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmovies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2551\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-1228f3f8b1ad>\u001b[0m in \u001b[0;36mcreate_csr\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mtfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdoc_occurences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mcsr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcsr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shape' is not defined"
     ]
    }
   ],
   "source": [
    "featurize(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T00:35:26.667080Z",
     "start_time": "2018-03-30T00:35:26.660874Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_split(ratings):\n",
    "    \"\"\"DONE.\n",
    "    Returns a random split of the ratings matrix into a training and testing set.\n",
    "    \"\"\"\n",
    "    test = set(range(len(ratings))[::1000])\n",
    "    train = sorted(set(range(len(ratings))) - test)\n",
    "    test = sorted(test)\n",
    "    return ratings.iloc[train], ratings.iloc[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T01:52:07.631272Z",
     "start_time": "2018-03-30T01:52:07.623103Z"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_sim(a, b):\n",
    "    \"\"\"\n",
    "    Compute the cosine similarity between two 1-d csr_matrices.\n",
    "    Each matrix represents the tf-idf feature vector of a movie.\n",
    "    Params:\n",
    "      a...A csr_matrix with shape (1, number_features)\n",
    "      b...A csr_matrix with shape (1, number_features)\n",
    "    Returns:\n",
    "      A float. The cosine similarity, defined as: dot(a, b) / ||a|| * ||b||\n",
    "      where ||a|| indicates the Euclidean norm (aka L2 norm) of vector a.\n",
    "    \"\"\"\n",
    "    normalize_a = np.sqrt(np.sum([item ** 2 for item in list(a.toarray())[0]]))\n",
    "    normalize_b = np.sqrt(np.sum([item ** 2 for item in list(b.toarray())[0]]))\n",
    "    cosine_sim = a.dot(b.T) / (normalize_a*normalize_b)\n",
    "    return cosine_sim.toarray()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T01:47:33.939472Z",
     "start_time": "2018-03-30T01:47:33.909323Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_predictions(movies, ratings_train, ratings_test):\n",
    "    \"\"\"\n",
    "    Using the ratings in ratings_train, predict the ratings for each\n",
    "    row in ratings_test.\n",
    "\n",
    "    To predict the rating of user u for movie i: Compute the weighted average\n",
    "    rating for every other movie that u has rated.  Restrict this weighted\n",
    "    average to movies that have a positive cosine similarity with movie\n",
    "    i. The weight for movie m corresponds to the cosine similarity between m\n",
    "    and i.\n",
    "\n",
    "    If there are no other movies with positive cosine similarity to use in the\n",
    "    prediction, use the mean rating of the target user in ratings_train as the\n",
    "    prediction.\n",
    "\n",
    "    Params:\n",
    "      movies..........The movies DataFrame.\n",
    "      ratings_train...The subset of ratings used for making predictions. These are the \"historical\" data.\n",
    "      ratings_test....The subset of ratings that need to predicted. These are the \"future\" data.\n",
    "    Returns:\n",
    "      A numpy array containing one predicted rating for each element of ratings_test.\n",
    "    \"\"\"\n",
    "    predictions = list()\n",
    "    for index, rating in ratings_test.iterrows():\n",
    "        cosine_sims = list()\n",
    "        user_ratings = ratings_train[ratings_train.userId == int(rating.userId)]\n",
    "        reference_features = movies[movies.movieId == int(rating.movieId)].features.iloc()[0]\n",
    "        for index, rating in user_ratings.iterrows():\n",
    "            movie_features = movies[movies.movieId == int(rating.movieId)].features.iloc()[0]\n",
    "            cosine_sims.append(cosine_sim(reference_features, movie_features))\n",
    "        user_ratings.loc[index, \"cosine\"] = cosine_sims\n",
    "        usefull_ratings = user_ratings[user_ratings.cosine != 0]\n",
    "        usefull_ratings.loc[index, \"weight\"] = usefull_ratings.cosine * usefull_ratings.rating\n",
    "        if len(usefull_ratings) != 0:\n",
    "            pred = usefull_ratings.weight.sum() / usefull_ratings.cosine.sum()\n",
    "        else:\n",
    "            pred = user_ratings.rating.mean()\n",
    "        predictions.append(pred)\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T20:56:21.943940Z",
     "start_time": "2018-03-29T20:56:21.939601Z"
    }
   },
   "outputs": [],
   "source": [
    "def mean_absolute_error(predictions, ratings_test):\n",
    "    \"\"\"DONE.\n",
    "    Return the mean absolute error of the predictions.\n",
    "    \"\"\"\n",
    "    return np.abs(predictions - np.array(ratings_test.rating)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T00:36:39.775638Z",
     "start_time": "2018-03-30T00:36:38.253461Z"
    }
   },
   "outputs": [],
   "source": [
    "download_data()\n",
    "path = 'ml-latest-small'\n",
    "ratings = pd.read_csv(path + os.path.sep + 'ratings.csv')\n",
    "movies = pd.read_csv(path + os.path.sep + 'movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T01:30:45.126939Z",
     "start_time": "2018-03-30T01:28:53.931235Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/sparse/compressed.py:774: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab:\n",
      "[('action', 0), ('adventure', 1), ('animation', 2), ('children', 3), ('comedy', 4), ('crime', 5), ('documentary', 6), ('drama', 7), ('fantasy', 8), ('film-noir', 9)]\n",
      "99903 training ratings; 101 testing ratings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antoinegargot/Library/Python/3.6/lib/python/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/antoinegargot/Library/Python/3.6/lib/python/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/antoinegargot/Library/Python/3.6/lib/python/site-packages/ipykernel_launcher.py:36: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error=nan\n",
      "[ 2.7945653   2.62385286  2.76558239  4.24064843  3.22115155  4.11423684\n",
      "  3.92040563  3.98286924  3.21565818  3.32692774]\n"
     ]
    }
   ],
   "source": [
    "movies = tokenize(movies)\n",
    "movies, vocab = featurize(movies)\n",
    "print('vocab:')\n",
    "print(sorted(vocab.items())[:10])\n",
    "ratings_train, ratings_test = train_test_split(ratings)\n",
    "print('%d training ratings; %d testing ratings' % (len(ratings_train), len(ratings_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T01:49:04.104807Z",
     "start_time": "2018-03-30T01:47:40.508955Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antoinegargot/Library/Python/3.6/lib/python/site-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/antoinegargot/Library/Python/3.6/lib/python/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "predictions = make_predictions(movies, ratings_train, ratings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T01:49:04.251740Z",
     "start_time": "2018-03-30T01:49:04.243542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error=0.787455\n",
      "[ 2.7945653   2.62385286  2.76558239  4.24064843  3.22115155  4.11423684\n",
      "  3.92040563  3.98286924  3.21565818  3.32692774  4.27272727  3.31632777\n",
      "  3.37410419  3.6070913   4.19457837  3.11741553  3.9041065   3.47972898\n",
      "  3.54681362  3.99956908  2.61430437  3.83085137  3.41293997  3.08717938\n",
      "  2.22706562  3.86792458  1.92705103  4.15639473  3.54094255  2.72964384\n",
      "  2.42921253  3.75428664  3.8156648   3.75633539  3.3759458   4.17401655\n",
      "  2.70290168  3.50817296  4.32120579  3.19255656  3.94989633  3.65050843\n",
      "  3.5248113   3.40363323  3.05135337  2.05252246  3.77652343  3.70554955\n",
      "  2.71055541  3.11391527  3.34696535  3.07691756  3.39595805  3.18173131\n",
      "  3.60142465  3.16071363  3.51946964  3.53780451  4.1255733   4.28514229\n",
      "  3.68441942  4.21954433  3.0047321   2.36989936  3.75551908  3.4704615\n",
      "  2.69670497  3.51192033  3.80634344  4.21522321  3.44948935  3.9882542\n",
      "  3.24598924  3.60530866  3.85374624  3.5997006   3.5862512   3.28802589\n",
      "  4.41838202  3.2957547   3.40068384  3.41884622  4.6650497   3.56384674\n",
      "  3.62690333  3.89524646  3.53504432  3.15952977  4.30713784  4.35358539\n",
      "  3.67228495  3.25542745  3.955992    3.01486045  2.96452671  2.94427238\n",
      "  4.6082861   3.28341429  4.02951428  3.83786995  4.        ]\n"
     ]
    }
   ],
   "source": [
    "print('error=%f' % mean_absolute_error(predictions, ratings_test))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
